{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri_D1Ndr3un2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0c37c463-209b-434e-db2f-bd3a53772298"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from bs4 import BeautifulSoup\n",
        "import re,string,unicodedata\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from string import punctuation\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OCBhNmGkGfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/Shared drives/capstone_aa')\n",
        "t=pd.read_csv('True.csv')\n",
        "f=pd.read_csv('Fake.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RobiN4eMkah3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t['category'] = 1\n",
        "f['category'] = 0\n",
        "\n",
        "df = pd.concat([t,f])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymuRSMUzk08j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a5d33f6f-e9b3-467d-bce8-4c3484b3e522"
      },
      "source": [
        "from nltk.corpus import stopwords           #for using stopwords\n",
        "from nltk.stem.porter import PorterStemmer  # for stemming\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import regex as re\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "cached_stopwords = stopwords.words('english')\n",
        "porter = PorterStemmer()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV58Ep1qlR2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import regex as re\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "cached_stopwords = stopwords.words('english')\n",
        "porter = PorterStemmer()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dXqWeu3ldg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_spec(text):\n",
        "    regex = r'[^a-zA-z0-9/s]'\n",
        "    text = re.sub(regex, ' ', text)\n",
        "    return text\n",
        "\n",
        "def process_title(title):\n",
        "  \n",
        "    title = title.lower()\n",
        "    title = replace_spec(title)\n",
        "    title=re.sub(\"donald trump\",\"trump \",title)    \n",
        "  \n",
        "    title_list = str.split(title)\n",
        "    \n",
        "    final_title =[]\n",
        "\n",
        "    for item in title_list:\n",
        "        if item not in cached_stopwords:\n",
        "            final_title.append(item)\n",
        "    \n",
        "    return \" \".join(final_title)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcgIX9uilpsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['text_final'] = df.text.apply(process_title)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP2TZ7ncmm5g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d7a39879-b557-44ca-d05e-704d9cd9515d"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_sNg0R0m7uk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stemSentence(sentence):\n",
        "    token_words=word_tokenize(sentence)\n",
        "    \n",
        "    stem_sentence=[]\n",
        "    for word in token_words:\n",
        "        stem_sentence.append(porter.stem(word))\n",
        "        stem_sentence.append(\" \")\n",
        "    return \"\".join(stem_sentence)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjRXD2dsm-u6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['t'] = df.text_final.apply(stemSentence)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oSuCCAMnFF4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2f28cfc1-9cd9-4f39-9fc4-063aa25fb49f"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(df.t,df.category)\n",
        "cv=CountVectorizer(min_df=0,max_df=1,ngram_range=(1,2))\n",
        "#transformed train reviews\n",
        "cv_train_reviews=cv.fit_transform(x_train)\n",
        "#transformed test reviews\n",
        "cv_test_reviews=cv.transform(x_test)\n",
        "\n",
        "print('BOW_cv_train:',cv_train_reviews.shape)\n",
        "print('BOW_cv_test:',cv_test_reviews.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BOW_cv_train: (33673, 1599009)\n",
            "BOW_cv_test: (11225, 1599009)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FLZwc1yni_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(units = 100 , activation = 'relu' , input_dim = cv_train_reviews.shape[1]))\n",
        "model.add(Dense(units = 50 , activation = 'relu'))\n",
        "model.add(Dense(units = 25 , activation = 'relu'))\n",
        "model.add(Dense(units = 10 , activation = 'relu'))\n",
        "model.add(Dense(units = 1 , activation = 'sigmoid'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3F522JbnyHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c2574315-f08c-478f-de49-59a9be21e736"
      },
      "source": [
        "model.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n",
        "model.fit(cv_train_reviews,y_train , epochs =5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "33673/33673 [==============================] - 2787s 83ms/step - loss: 0.6914 - accuracy: 0.5232\n",
            "Epoch 2/5\n",
            " 6528/33673 [====>.........................] - ETA: 36:21 - loss: 0.1013 - accuracy: 0.9658"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs3uMofFmnWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict(cv_test_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHa4q5xusQ8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(pred)):\n",
        "    if(pred[i] > 0.5):\n",
        "        pred[i] = 1\n",
        "    else:\n",
        "        pred[i] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6yPhDEDtaLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_score(pred,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXB8r8WwrD3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm_cv = confusion_matrix(y_test,pred)\n",
        "cm_cv"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}